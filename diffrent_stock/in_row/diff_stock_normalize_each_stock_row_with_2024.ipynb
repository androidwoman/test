{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Q9eCwB8v-hsQ",
        "outputId": "c7d2769d-4bae-4a92-e31b-9eccf4c0f69b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.48)\n",
            "Collecting timesfm==1.1.0\n",
            "  Downloading timesfm-1.1.0-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting einshape>=1.0.0 (from timesfm==1.1.0)\n",
            "  Downloading einshape-1.0-py3-none-any.whl.metadata (706 bytes)\n",
            "Requirement already satisfied: huggingface_hub>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub[cli]>=0.23.0->timesfm==1.1.0) (0.26.2)\n",
            "Requirement already satisfied: jax>=0.4.26 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]>=0.4.26->timesfm==1.1.0) (0.4.33)\n",
            "Requirement already satisfied: jaxlib>=0.4.26 in /usr/local/lib/python3.10/dist-packages (from timesfm==1.1.0) (0.4.33)\n",
            "Requirement already satisfied: numpy>=1.26.4 in /usr/local/lib/python3.10/dist-packages (from timesfm==1.1.0) (1.26.4)\n",
            "Requirement already satisfied: pandas>=2.1.4 in /usr/local/lib/python3.10/dist-packages (from timesfm==1.1.0) (2.2.2)\n",
            "Collecting paxml>=1.4.0 (from timesfm==1.1.0)\n",
            "  Downloading paxml-1.4.0-py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from timesfm==1.1.0) (1.5.2)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.10/dist-packages (from timesfm==1.1.0) (0.13.0)\n",
            "Collecting utilsforecast>=0.1.10 (from timesfm==1.1.0)\n",
            "  Downloading utilsforecast-0.2.8-py3-none-any.whl.metadata (7.4 kB)\n",
            "Requirement already satisfied: wandb>=0.17.5 in /usr/local/lib/python3.10/dist-packages (from timesfm==1.1.0) (0.18.6)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (5.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.7)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from einshape>=1.0.0->timesfm==1.1.0) (1.4.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm==1.1.0) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm==1.1.0) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm==1.1.0) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm==1.1.0) (6.0.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm==1.1.0) (4.66.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub>=0.23.0->huggingface_hub[cli]>=0.23.0->timesfm==1.1.0) (4.12.2)\n",
            "Collecting InquirerPy==0.3.4 (from huggingface_hub[cli]>=0.23.0->timesfm==1.1.0)\n",
            "  Downloading InquirerPy-0.3.4-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting pfzy<0.4.0,>=0.3.1 (from InquirerPy==0.3.4->huggingface_hub[cli]>=0.23.0->timesfm==1.1.0)\n",
            "  Downloading pfzy-0.3.4-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: prompt-toolkit<4.0.0,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from InquirerPy==0.3.4->huggingface_hub[cli]>=0.23.0->timesfm==1.1.0) (3.0.48)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.26->jax[cuda12]>=0.4.26->timesfm==1.1.0) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.26->jax[cuda12]>=0.4.26->timesfm==1.1.0) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.10 in /usr/local/lib/python3.10/dist-packages (from jax>=0.4.26->jax[cuda12]>=0.4.26->timesfm==1.1.0) (1.13.1)\n",
            "Requirement already satisfied: jax-cuda12-plugin<=0.4.33,>=0.4.33 in /usr/local/lib/python3.10/dist-packages (from jax-cuda12-plugin[with_cuda]<=0.4.33,>=0.4.33; extra == \"cuda12\"->jax[cuda12]>=0.4.26->timesfm==1.1.0) (0.4.33)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1.4->timesfm==1.1.0) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.1.4->timesfm==1.1.0) (2024.2)\n",
            "Collecting clu==0.0.11 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading clu-0.0.11-py3-none-any.whl.metadata (1.9 kB)\n",
            "Collecting etils==1.7.0 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading etils-1.7.0-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting flax==0.8.2 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading flax-0.8.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting graphviz==0.20.1 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading graphviz-0.20.1-py3-none-any.whl.metadata (12 kB)\n",
            "INFO: pip is looking at multiple versions of paxml to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax[cuda12]>=0.4.26 (from timesfm==1.1.0)\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "INFO: pip is looking at multiple versions of jax[cuda12] to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.4.33-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.4.29-py3-none-any.whl.metadata (23 kB)\n",
            "  Downloading jax-0.4.28-py3-none-any.whl.metadata (23 kB)\n",
            "INFO: pip is still looking at multiple versions of jax[cuda12] to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading jax-0.4.27-py3-none-any.whl.metadata (23 kB)\n",
            "  Downloading jax-0.4.26-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting jaxlib>=0.4.26 (from timesfm==1.1.0)\n",
            "  Downloading jaxlib-0.4.35-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "  Downloading jaxlib-0.4.34-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax-cuda12-plugin<=0.4.35,>=0.4.34 (from jax-cuda12-plugin[with_cuda]<=0.4.35,>=0.4.34; extra == \"cuda12\"->jax[cuda12]>=0.4.26->timesfm==1.1.0)\n",
            "  Downloading jax_cuda12_plugin-0.4.35-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax-cuda12-plugin<=0.4.34,>=0.4.34 (from jax-cuda12-plugin[with_cuda]<=0.4.34,>=0.4.34; extra == \"cuda12\"->jax[cuda12]>=0.4.26->timesfm==1.1.0)\n",
            "  Downloading jax_cuda12_plugin-0.4.34-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting jaxlib>=0.4.26 (from timesfm==1.1.0)\n",
            "  Downloading jaxlib-0.4.31-cp310-cp310-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax-cuda12-plugin<=0.4.31,>=0.4.31 (from jax-cuda12-plugin[with_cuda]<=0.4.31,>=0.4.31; extra == \"cuda12\"->jax[cuda12]>=0.4.26->timesfm==1.1.0)\n",
            "  Downloading jax_cuda12_plugin-0.4.31-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jaxlib>=0.4.26 (from timesfm==1.1.0)\n",
            "  Downloading jaxlib-0.4.30-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax-cuda12-plugin<=0.4.30,>=0.4.30 (from jax-cuda12-plugin[with_cuda]<=0.4.30,>=0.4.30; extra == \"cuda12\"->jax[cuda12]>=0.4.26->timesfm==1.1.0)\n",
            "  Downloading jax_cuda12_plugin-0.4.30-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "INFO: pip is still looking at multiple versions of paxml to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jaxlib>=0.4.26 (from timesfm==1.1.0)\n",
            "  Downloading jaxlib-0.4.29-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting jax-cuda12-plugin==0.4.29 (from jax[cuda12]>=0.4.26->timesfm==1.1.0)\n",
            "  Downloading jax_cuda12_plugin-0.4.29-cp310-cp310-manylinux2014_x86_64.whl.metadata (560 bytes)\n",
            "Requirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]>=0.4.26->timesfm==1.1.0) (12.6.3.3)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12>=12.1.105 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]>=0.4.26->timesfm==1.1.0) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cuda-nvcc-cu12>=12.1.105 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]>=0.4.26->timesfm==1.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]>=0.4.26->timesfm==1.1.0) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12<10.0,>=9.0 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]>=0.4.26->timesfm==1.1.0) (9.5.1.17)\n",
            "Requirement already satisfied: nvidia-cufft-cu12>=11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]>=0.4.26->timesfm==1.1.0) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12>=11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]>=0.4.26->timesfm==1.1.0) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12>=12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]>=0.4.26->timesfm==1.1.0) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12>=2.18.1 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]>=0.4.26->timesfm==1.1.0) (2.23.4)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12>=12.1.105 in /usr/local/lib/python3.10/dist-packages (from jax[cuda12]>=0.4.26->timesfm==1.1.0) (12.6.77)\n",
            "Collecting jax-cuda12-pjrt==0.4.29 (from jax-cuda12-plugin==0.4.29->jax[cuda12]>=0.4.26->timesfm==1.1.0)\n",
            "  Downloading jax_cuda12_pjrt-0.4.29-py3-none-manylinux2014_x86_64.whl.metadata (349 bytes)\n",
            "Collecting jaxlib>=0.4.26 (from timesfm==1.1.0)\n",
            "  Downloading jaxlib-0.4.28-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting jax-cuda12-plugin==0.4.28 (from jax[cuda12]>=0.4.26->timesfm==1.1.0)\n",
            "  Downloading jax_cuda12_plugin-0.4.28-cp310-cp310-manylinux2014_x86_64.whl.metadata (560 bytes)\n",
            "Collecting nvidia-cudnn-cu12<9.0,>=8.9.2.26 (from jax[cuda12]>=0.4.26->timesfm==1.1.0)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting jax-cuda12-pjrt==0.4.28 (from jax-cuda12-plugin==0.4.28->jax[cuda12]>=0.4.26->timesfm==1.1.0)\n",
            "  Downloading jax_cuda12_pjrt-0.4.28-py3-none-manylinux2014_x86_64.whl.metadata (349 bytes)\n",
            "Collecting jaxlib>=0.4.26 (from timesfm==1.1.0)\n",
            "  Downloading jaxlib-0.4.27-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting jax-cuda12-plugin==0.4.27 (from jax[cuda12]>=0.4.26->timesfm==1.1.0)\n",
            "  Downloading jax_cuda12_plugin-0.4.27-cp310-cp310-manylinux2014_x86_64.whl.metadata (560 bytes)\n",
            "Collecting jax-cuda12-pjrt==0.4.27 (from jax-cuda12-plugin==0.4.27->jax[cuda12]>=0.4.26->timesfm==1.1.0)\n",
            "  Downloading jax_cuda12_pjrt-0.4.27-py3-none-manylinux2014_x86_64.whl.metadata (349 bytes)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting jaxlib>=0.4.26 (from timesfm==1.1.0)\n",
            "  Downloading jaxlib-0.4.26-cp310-cp310-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting jax-cuda12-plugin==0.4.26 (from jax[cuda12]>=0.4.26->timesfm==1.1.0)\n",
            "  Downloading jax_cuda12_plugin-0.4.26-cp310-cp310-manylinux2014_x86_64.whl.metadata (560 bytes)\n",
            "Collecting jax-cuda12-pjrt==0.4.26 (from jax-cuda12-plugin==0.4.26->jax[cuda12]>=0.4.26->timesfm==1.1.0)\n",
            "  Downloading jax_cuda12_pjrt-0.4.26-py3-none-manylinux2014_x86_64.whl.metadata (349 bytes)\n",
            "Collecting lingvo==0.12.7 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading lingvo-0.12.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting orbax-checkpoint==0.5.9 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading orbax_checkpoint-0.5.9-py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting praxis==1.4.0 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading praxis-1.4.0-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting protobuf==3.19.6 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (787 bytes)\n",
            "Collecting pyglove==0.4.4 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading pyglove-0.4.4-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting seqio-nightly==0.0.17.dev20231010 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading seqio_nightly-0.0.17.dev20231010-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.9/51.9 kB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting t5==0.9.4 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading t5-0.9.4-py2.py3-none-any.whl.metadata (25 kB)\n",
            "Collecting tensorflow-datasets==4.8.3 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading tensorflow_datasets-4.8.3-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting tensorflow-metadata==1.12.0 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading tensorflow_metadata-1.12.0-py3-none-any.whl.metadata (2.2 kB)\n",
            "Collecting tensorflow-text~=2.9.0 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading tensorflow_text-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting tensorflow~=2.9.2 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading tensorflow-2.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting tensorstore==0.1.55 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading tensorstore-0.1.55-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting tfds-nightly==4.8.3.dev202303280045 (from paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading tfds_nightly-4.8.3.dev202303280045-py3-none-any.whl.metadata (9.0 kB)\n",
            "Collecting ml-collections (from clu==0.0.11->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading ml_collections-1.0.0-py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from clu==0.0.11->paxml>=1.4.0->timesfm==1.1.0) (1.16.0)\n",
            "Requirement already satisfied: msgpack in /usr/local/lib/python3.10/dist-packages (from flax==0.8.2->paxml>=1.4.0->timesfm==1.1.0) (1.1.0)\n",
            "Requirement already satisfied: optax in /usr/local/lib/python3.10/dist-packages (from flax==0.8.2->paxml>=1.4.0->timesfm==1.1.0) (0.2.3)\n",
            "Requirement already satisfied: rich>=11.1 in /usr/local/lib/python3.10/dist-packages (from flax==0.8.2->paxml>=1.4.0->timesfm==1.1.0) (13.9.4)\n",
            "Requirement already satisfied: attrs in /usr/local/lib/python3.10/dist-packages (from lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (24.2.0)\n",
            "Collecting graph-compression-google-research (from lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading graph_compression_google_research-0.0.4-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.10/dist-packages (from lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (5.5.6)\n",
            "Collecting jupyter-http-over-ws (from lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading jupyter_http_over_ws-0.0.8-py2.py3-none-any.whl.metadata (1.1 kB)\n",
            "Collecting jupyter (from lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading jupyter-1.1.1-py2.py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (3.8.0)\n",
            "Collecting model-pruning-google-research (from lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading model_pruning_google_research-0.0.5-py3-none-any.whl.metadata (627 bytes)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (11.0.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.2.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (1.13.1)\n",
            "Requirement already satisfied: tensorflow-hub in /usr/local/lib/python3.10/dist-packages (from lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.16.1)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.10/dist-packages (from orbax-checkpoint==0.5.9->paxml>=1.4.0->timesfm==1.1.0) (1.6.0)\n",
            "Requirement already satisfied: chex>=0.1.85 in /usr/local/lib/python3.10/dist-packages (from praxis==1.4.0->paxml>=1.4.0->timesfm==1.1.0) (0.1.87)\n",
            "Collecting einops==0.7.0 (from praxis==1.4.0->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting fiddle==0.3.0 (from praxis==1.4.0->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading fiddle-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting jax-bitempered-loss==0.0.2 (from praxis==1.4.0->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading jax_bitempered_loss-0.0.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "Collecting jaxtyping==0.2.28 (from praxis==1.4.0->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading jaxtyping-0.2.28-py3-none-any.whl.metadata (6.4 kB)\n",
            "Collecting opt-einsum (from jax[cuda12]>=0.4.26->timesfm==1.1.0)\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting optax-shampoo==0.0.6 (from praxis==1.4.0->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading optax_shampoo-0.0.6-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting optax (from flax==0.8.2->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading optax-0.2.2-py3-none-any.whl.metadata (8.1 kB)\n",
            "Collecting sentencepiece (from lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
            "Collecting typeguard==2.13.3 (from praxis==1.4.0->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading typeguard-2.13.3-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: docstring-parser>=0.12 in /usr/local/lib/python3.10/dist-packages (from pyglove==0.4.4->paxml>=1.4.0->timesfm==1.1.0) (0.16)\n",
            "Requirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from seqio-nightly==0.0.17.dev20231010->paxml>=1.4.0->timesfm==1.1.0) (0.8.1)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.10/dist-packages (from t5==0.9.4->paxml>=1.4.0->timesfm==1.1.0) (2.16.0)\n",
            "Requirement already satisfied: immutabledict in /usr/local/lib/python3.10/dist-packages (from t5==0.9.4->paxml>=1.4.0->timesfm==1.1.0) (4.2.0)\n",
            "Requirement already satisfied: gin-config in /usr/local/lib/python3.10/dist-packages (from t5==0.9.4->paxml>=1.4.0->timesfm==1.1.0) (0.5.0)\n",
            "Collecting mesh-tensorflow>=0.1.13 (from mesh-tensorflow[transformer]>=0.1.13->t5==0.9.4->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading mesh_tensorflow-0.1.21-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from t5==0.9.4->paxml>=1.4.0->timesfm==1.1.0) (3.9.1)\n",
            "Collecting rouge-score>=0.1.2 (from t5==0.9.4->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu (from t5==0.9.4->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading sacrebleu-2.4.3-py3-none-any.whl.metadata (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from t5==0.9.4->paxml>=1.4.0->timesfm==1.1.0) (4.46.2)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.8.3->paxml>=1.4.0->timesfm==1.1.0) (8.1.7)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.8.3->paxml>=1.4.0->timesfm==1.1.0) (0.1.8)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.8.3->paxml>=1.4.0->timesfm==1.1.0) (2.3)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.8.3->paxml>=1.4.0->timesfm==1.1.0) (5.9.5)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.8.3->paxml>=1.4.0->timesfm==1.1.0) (2.5.0)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from tensorflow-datasets==4.8.3->paxml>=1.4.0->timesfm==1.1.0) (0.10.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2,>=1.52.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-metadata==1.12.0->paxml>=1.4.0->timesfm==1.1.0) (1.65.0)\n",
            "Requirement already satisfied: array-record in /usr/local/lib/python3.10/dist-packages (from tfds-nightly==4.8.3.dev202303280045->paxml>=1.4.0->timesfm==1.1.0) (0.5.1)\n",
            "Collecting libcst (from fiddle==0.3.0->praxis==1.4.0->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading libcst-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (17 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.8.30)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->timesfm==1.1.0) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.2.2->timesfm==1.1.0) (3.5.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.12.3->timesfm==1.1.0) (1.5.4)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.5->timesfm==1.1.0) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.5->timesfm==1.1.0) (3.1.43)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.5->timesfm==1.1.0) (2.18.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.5->timesfm==1.1.0) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.17.5->timesfm==1.1.0) (75.1.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.17.5->timesfm==1.1.0) (4.0.11)\n",
            "Collecting nvidia-cuda-nvrtc-cu12 (from nvidia-cudnn-cu12<9.0,>=8.9.2.26->jax[cuda12]>=0.4.26->timesfm==1.1.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax==0.8.2->paxml>=1.4.0->timesfm==1.1.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1->flax==0.8.2->paxml>=1.4.0->timesfm==1.1.0) (2.18.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0) (1.6.3)\n",
            "Collecting flatbuffers<2,>=1.12 (from tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl.metadata (872 bytes)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0) (1.67.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0) (3.12.1)\n",
            "Collecting keras<2.10.0,>=2.9.0rc0 (from tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Collecting keras-preprocessing>=1.1.1 (from tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0) (18.1.1)\n",
            "Collecting tensorboard<2.10,>=2.9 (from tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0) (0.37.1)\n",
            "Collecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0) (0.44.0)\n",
            "INFO: pip is looking at multiple versions of chex to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting chex>=0.1.85 (from praxis==1.4.0->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading chex-0.1.86-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: toolz>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chex>=0.1.85->praxis==1.4.0->paxml>=1.4.0->timesfm==1.1.0) (0.12.1)\n",
            "Requirement already satisfied: importlib_resources in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets==4.8.3->paxml>=1.4.0->timesfm==1.1.0) (6.4.5)\n",
            "Requirement already satisfied: zipp in /usr/local/lib/python3.10/dist-packages (from etils[enp,epath]>=0.9.0->tensorflow-datasets==4.8.3->paxml>=1.4.0->timesfm==1.1.0) (3.20.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.17.5->timesfm==1.1.0) (5.0.1)\n",
            "INFO: pip is looking at multiple versions of googleapis-common-protos to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting googleapis-common-protos<2,>=1.52.0 (from tensorflow-metadata==1.12.0->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "  Downloading googleapis_common_protos-1.64.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "  Downloading googleapis_common_protos-1.63.2-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "  Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1->flax==0.8.2->paxml>=1.4.0->timesfm==1.1.0) (0.1.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from mesh-tensorflow>=0.1.13->mesh-tensorflow[transformer]>=0.1.13->t5==0.9.4->paxml>=1.4.0->timesfm==1.1.0) (1.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit<4.0.0,>=3.0.1->InquirerPy==0.3.4->huggingface_hub[cli]>=0.23.0->timesfm==1.1.0) (0.2.13)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0) (2.27.0)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.10,>=2.9->tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0) (3.7)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.10,>=2.9->tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.10,>=2.9->tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0) (3.1.3)\n",
            "Requirement already satisfied: tf-keras>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-hub->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (2.17.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.7.0->t5==0.9.4->paxml>=1.4.0->timesfm==1.1.0) (2024.9.11)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.7.0->t5==0.9.4->paxml>=1.4.0->timesfm==1.1.0) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from transformers>=2.7.0->t5==0.9.4->paxml>=1.4.0->timesfm==1.1.0) (0.20.3)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.10/dist-packages (from ipykernel->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.2.0)\n",
            "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (7.34.0)\n",
            "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from ipykernel->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (5.7.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.10/dist-packages (from ipykernel->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipykernel->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (6.3.3)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.10/dist-packages (from jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (6.5.5)\n",
            "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.10/dist-packages (from jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (6.1.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.10/dist-packages (from jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (7.16.4)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.10/dist-packages (from jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (7.7.1)\n",
            "Collecting jupyterlab (from jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading jupyterlab-4.3.0-py3-none-any.whl.metadata (16 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (4.54.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (3.2.0)\n",
            "Collecting portalocker (from sacrebleu->t5==0.9.4->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading portalocker-2.10.1-py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu->t5==0.9.4->paxml>=1.4.0->timesfm==1.1.0) (0.9.0)\n",
            "Collecting colorama (from sacrebleu->t5==0.9.4->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (1.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0) (1.3.1)\n",
            "Collecting jedi>=0.16 (from ipython>=5.0.0->ipykernel->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython>=5.0.0->ipykernel->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (4.9.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (3.1.4)\n",
            "Requirement already satisfied: pyzmq<25,>=17 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (24.0.1)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (23.1.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (5.7.2)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (5.10.4)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (1.8.3)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.18.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.21.0)\n",
            "Requirement already satisfied: nbclassic>=0.4.7 in /usr/local/lib/python3.10/dist-packages (from notebook->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (1.1.0)\n",
            "Requirement already satisfied: bleach!=5.0.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (6.2.0)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.7.1)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.3.0)\n",
            "Requirement already satisfied: markupsafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (3.0.2)\n",
            "Requirement already satisfied: mistune<4,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (3.0.2)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.10.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (1.5.1)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.10/dist-packages (from nbconvert->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (1.4.0)\n",
            "INFO: pip is looking at multiple versions of tf-keras to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tf-keras>=2.14.1 (from tensorflow-hub->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading tf_keras-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "  Downloading tf_keras-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
            "  Downloading tf_keras-2.15.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (3.6.10)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ipywidgets->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (3.0.13)\n",
            "Collecting async-lru>=1.0.0 (from jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading async_lru-2.0.4-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: httpx>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.27.2)\n",
            "Collecting ipykernel (from lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading ipykernel-6.29.5-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jupyter-lsp>=2.0.0 (from jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading jupyter_lsp-2.2.5-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting jupyter-server<3,>=2.4.0 (from jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading jupyter_server-2.14.2-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting jupyterlab-server<3,>=2.27.1 (from jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading jupyterlab_server-2.27.3-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: notebook-shim>=0.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.2.4)\n",
            "Requirement already satisfied: tomli>=1.2.2 in /usr/local/lib/python3.10/dist-packages (from jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (2.0.2)\n",
            "Collecting comm>=0.1.1 (from ipykernel->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading comm-0.2.2-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: debugpy>=1.6.5 in /usr/local/lib/python3.10/dist-packages (from ipykernel->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (1.8.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (3.7.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (1.0.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.25.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.25.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.14.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython>=5.0.0->ipykernel->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.8.4)\n",
            "Collecting jupyter-client<8,>=5.3.4 (from notebook->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading jupyter_client-7.4.9-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting jupyter-events>=0.9.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading jupyter_events-0.10.0-py3-none-any.whl.metadata (5.9 kB)\n",
            "Collecting jupyter-server-terminals>=0.4.4 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting overrides>=5.0 (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: websocket-client>=1.7 in /usr/local/lib/python3.10/dist-packages (from jupyter-server<3,>=2.4.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (1.8.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from jupyter-client<8,>=5.3.4->notebook->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.4)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.10/dist-packages (from argon2-cffi->notebook->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (21.2.0)\n",
            "Collecting json5>=0.9.0 (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading json5-0.9.28-py3-none-any.whl.metadata (32 kB)\n",
            "Requirement already satisfied: jsonschema>=4.18.0 in /usr/local/lib/python3.10/dist-packages (from jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (4.23.0)\n",
            "Requirement already satisfied: fastjsonschema>=2.15 in /usr/local/lib/python3.10/dist-packages (from nbformat->notebook->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (2.20.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython>=5.0.0->ipykernel->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.7.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow~=2.9.2->paxml>=1.4.0->timesfm==1.1.0) (3.2.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.25.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (1.2.2)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=4.18.0->jupyterlab-server<3,>=2.27.1->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (0.21.0)\n",
            "Collecting python-json-logger>=2.0.4 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading python_json_logger-2.0.7-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting rfc3339-validator (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting rfc3986-validator>=0.1.1 (from jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: cffi>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from argon2-cffi-bindings->argon2-cffi->notebook->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0.1->argon2-cffi-bindings->argon2-cffi->notebook->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (2.22)\n",
            "Collecting fqdn (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading fqdn-1.5.1-py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting isoduration (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading isoduration-20.11.0-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jsonpointer>1.13 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (3.0.0)\n",
            "Collecting uri-template (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading uri_template-1.3.0-py3-none-any.whl.metadata (8.8 kB)\n",
            "Requirement already satisfied: webcolors>=24.6.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0) (24.8.0)\n",
            "Collecting arrow>=0.15.0 (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading arrow-1.3.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting types-python-dateutil>=2.8.10 (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.9.0->jupyter-server<3,>=2.4.0->jupyterlab->jupyter->lingvo==0.12.7->paxml>=1.4.0->timesfm==1.1.0)\n",
            "  Downloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl.metadata (1.9 kB)\n",
            "Downloading timesfm-1.1.0-py3-none-any.whl (37 kB)\n",
            "Downloading einshape-1.0-py3-none-any.whl (21 kB)\n",
            "Downloading InquirerPy-0.3.4-py3-none-any.whl (67 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.7/67.7 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jaxlib-0.4.26-cp310-cp310-manylinux2014_x86_64.whl (78.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax_cuda12_plugin-0.4.26-cp310-cp310-manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m39.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax_cuda12_pjrt-0.4.26-py3-none-manylinux2014_x86_64.whl (85.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.7/85.7 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax-0.4.26-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading paxml-1.4.0-py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.2/440.2 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading clu-0.0.11-py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.4/101.4 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading etils-1.7.0-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flax-0.8.2-py3-none-any.whl (686 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m686.8/686.8 kB\u001b[0m \u001b[31m42.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphviz-0.20.1-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lingvo-0.12.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orbax_checkpoint-0.5.9-py3-none-any.whl (168 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.0/168.0 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading praxis-1.4.0-py3-none-any.whl (772 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m772.5/772.5 kB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-3.19.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyglove-0.4.4-py3-none-any.whl (577 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m577.8/577.8 kB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading seqio_nightly-0.0.17.dev20231010-py3-none-any.whl (353 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m353.1/353.1 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading t5-0.9.4-py2.py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.5/164.5 kB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_datasets-4.8.3-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_metadata-1.12.0-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorstore-0.1.55-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/14.3 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tfds_nightly-4.8.3.dev202303280045-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fiddle-0.3.0-py3-none-any.whl (419 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m419.8/419.8 kB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax_bitempered_loss-0.0.2-py3-none-any.whl (12 kB)\n",
            "Downloading jaxtyping-0.2.28-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optax-0.2.2-py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading optax_shampoo-0.0.6-py3-none-any.whl (32 kB)\n",
            "Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typeguard-2.13.3-py3-none-any.whl (17 kB)\n",
            "Downloading utilsforecast-0.2.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/41.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-8.9.7.29-py3-none-manylinux1_x86_64.whl (704.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m704.7/704.7 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow-2.9.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.8/511.8 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_text-2.9.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m102.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading chex-0.1.86-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading googleapis_common_protos-1.63.1-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.2/229.2 kB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m70.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mesh_tensorflow-0.1.21-py3-none-any.whl (385 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.2/385.2 kB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pfzy-0.3.4-py3-none-any.whl (8.5 kB)\n",
            "Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graph_compression_google_research-0.0.4-py3-none-any.whl (90 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter-1.1.1-py2.py3-none-any.whl (2.7 kB)\n",
            "Downloading jupyter_http_over_ws-0.0.8-py2.py3-none-any.whl (18 kB)\n",
            "Downloading ml_collections-1.0.0-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading model_pruning_google_research-0.0.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.6.77-py3-none-manylinux2014_x86_64.whl (23.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m85.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sacrebleu-2.4.3-py3-none-any.whl (103 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.0/104.0 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m107.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tf_keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Downloading jupyterlab-4.3.0-py3-none-any.whl (11.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.7/11.7 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ipykernel-6.29.5-py3-none-any.whl (117 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/117.2 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Downloading libcst-1.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m79.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading portalocker-2.10.1-py3-none-any.whl (18 kB)\n",
            "Downloading async_lru-2.0.4-py3-none-any.whl (6.1 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_lsp-2.2.5-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/69.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_server-2.14.2-py3-none-any.whl (383 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.6/383.6 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyter_client-7.4.9-py3-none-any.whl (133 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.5/133.5 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jupyterlab_server-2.27.3-py3-none-any.whl (59 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.7/59.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading json5-0.9.28-py3-none-any.whl (30 kB)\n",
            "Downloading jupyter_events-0.10.0-py3-none-any.whl (18 kB)\n",
            "Downloading jupyter_server_terminals-0.5.3-py3-none-any.whl (13 kB)\n",
            "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Downloading python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)\n",
            "Downloading rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)\n",
            "Downloading rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)\n",
            "Downloading fqdn-1.5.1-py3-none-any.whl (9.1 kB)\n",
            "Downloading isoduration-20.11.0-py3-none-any.whl (11 kB)\n",
            "Downloading uri_template-1.3.0-py3-none-any.whl (11 kB)\n",
            "Downloading arrow-1.3.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading types_python_dateutil-2.9.0.20241003-py3-none-any.whl (9.7 kB)\n",
            "Building wheels for collected packages: rouge-score\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=6ef445b3eff6486c68ba8475e114ce5c501785d17d158b09f09323a9423dea9e\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "Successfully built rouge-score\n",
            "Installing collected packages: tensorboard-plugin-wit, sentencepiece, keras, jax-cuda12-pjrt, flatbuffers, uri-template, types-python-dateutil, typeguard, tf-keras, tensorflow-estimator, tensorboard-data-server, rfc3986-validator, rfc3339-validator, python-json-logger, pyglove, protobuf, portalocker, pfzy, overrides, optax-shampoo, opt-einsum, nvidia-cuda-nvrtc-cu12, model-pruning-google-research, ml-collections, mesh-tensorflow, libcst, keras-preprocessing, json5, jedi, jax-cuda12-plugin, jax-bitempered-loss, graphviz, graph-compression-google-research, gast, fqdn, etils, einshape, einops, comm, colorama, async-lru, tensorstore, sacrebleu, rouge-score, nvidia-cudnn-cu12, jupyter-server-terminals, jupyter-client, jaxtyping, jaxlib, jax, InquirerPy, googleapis-common-protos, fiddle, arrow, utilsforecast, tensorflow-metadata, isoduration, ipykernel, google-auth-oauthlib, chex, tensorflow-datasets, tensorboard, orbax-checkpoint, optax, tfds-nightly, tensorflow, jupyter-events, flax, tensorflow-text, clu, seqio-nightly, jupyter-server, t5, jupyterlab-server, jupyter-lsp, jupyterlab, jupyter-http-over-ws, jupyter, lingvo, praxis, paxml, timesfm\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.2.0\n",
            "    Uninstalling sentencepiece-0.2.0:\n",
            "      Successfully uninstalled sentencepiece-0.2.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.4.1\n",
            "    Uninstalling keras-3.4.1:\n",
            "      Successfully uninstalled keras-3.4.1\n",
            "  Attempting uninstall: jax-cuda12-pjrt\n",
            "    Found existing installation: jax-cuda12-pjrt 0.4.33\n",
            "    Uninstalling jax-cuda12-pjrt-0.4.33:\n",
            "      Successfully uninstalled jax-cuda12-pjrt-0.4.33\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 24.3.25\n",
            "    Uninstalling flatbuffers-24.3.25:\n",
            "      Successfully uninstalled flatbuffers-24.3.25\n",
            "  Attempting uninstall: typeguard\n",
            "    Found existing installation: typeguard 4.4.1\n",
            "    Uninstalling typeguard-4.4.1:\n",
            "      Successfully uninstalled typeguard-4.4.1\n",
            "  Attempting uninstall: tf-keras\n",
            "    Found existing installation: tf_keras 2.17.0\n",
            "    Uninstalling tf_keras-2.17.0:\n",
            "      Successfully uninstalled tf_keras-2.17.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.5\n",
            "    Uninstalling protobuf-4.25.5:\n",
            "      Successfully uninstalled protobuf-4.25.5\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt_einsum 3.4.0\n",
            "    Uninstalling opt_einsum-3.4.0:\n",
            "      Successfully uninstalled opt_einsum-3.4.0\n",
            "  Attempting uninstall: jax-cuda12-plugin\n",
            "    Found existing installation: jax-cuda12-plugin 0.4.33\n",
            "    Uninstalling jax-cuda12-plugin-0.4.33:\n",
            "      Successfully uninstalled jax-cuda12-plugin-0.4.33\n",
            "  Attempting uninstall: graphviz\n",
            "    Found existing installation: graphviz 0.20.3\n",
            "    Uninstalling graphviz-0.20.3:\n",
            "      Successfully uninstalled graphviz-0.20.3\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: etils\n",
            "    Found existing installation: etils 1.10.0\n",
            "    Uninstalling etils-1.10.0:\n",
            "      Successfully uninstalled etils-1.10.0\n",
            "  Attempting uninstall: einops\n",
            "    Found existing installation: einops 0.8.0\n",
            "    Uninstalling einops-0.8.0:\n",
            "      Successfully uninstalled einops-0.8.0\n",
            "  Attempting uninstall: tensorstore\n",
            "    Found existing installation: tensorstore 0.1.67\n",
            "    Uninstalling tensorstore-0.1.67:\n",
            "      Successfully uninstalled tensorstore-0.1.67\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.5.1.17\n",
            "    Uninstalling nvidia-cudnn-cu12-9.5.1.17:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.5.1.17\n",
            "  Attempting uninstall: jupyter-client\n",
            "    Found existing installation: jupyter-client 6.1.12\n",
            "    Uninstalling jupyter-client-6.1.12:\n",
            "      Successfully uninstalled jupyter-client-6.1.12\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.4.33\n",
            "    Uninstalling jaxlib-0.4.33:\n",
            "      Successfully uninstalled jaxlib-0.4.33\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.4.33\n",
            "    Uninstalling jax-0.4.33:\n",
            "      Successfully uninstalled jax-0.4.33\n",
            "  Attempting uninstall: googleapis-common-protos\n",
            "    Found existing installation: googleapis-common-protos 1.65.0\n",
            "    Uninstalling googleapis-common-protos-1.65.0:\n",
            "      Successfully uninstalled googleapis-common-protos-1.65.0\n",
            "  Attempting uninstall: tensorflow-metadata\n",
            "    Found existing installation: tensorflow-metadata 1.13.1\n",
            "    Uninstalling tensorflow-metadata-1.13.1:\n",
            "      Successfully uninstalled tensorflow-metadata-1.13.1\n",
            "  Attempting uninstall: ipykernel\n",
            "    Found existing installation: ipykernel 5.5.6\n",
            "    Uninstalling ipykernel-5.5.6:\n",
            "      Successfully uninstalled ipykernel-5.5.6\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.1\n",
            "    Uninstalling google-auth-oauthlib-1.2.1:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.1\n",
            "  Attempting uninstall: chex\n",
            "    Found existing installation: chex 0.1.87\n",
            "    Uninstalling chex-0.1.87:\n",
            "      Successfully uninstalled chex-0.1.87\n",
            "  Attempting uninstall: tensorflow-datasets\n",
            "    Found existing installation: tensorflow-datasets 4.9.7\n",
            "    Uninstalling tensorflow-datasets-4.9.7:\n",
            "      Successfully uninstalled tensorflow-datasets-4.9.7\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.17.0\n",
            "    Uninstalling tensorboard-2.17.0:\n",
            "      Successfully uninstalled tensorboard-2.17.0\n",
            "  Attempting uninstall: orbax-checkpoint\n",
            "    Found existing installation: orbax-checkpoint 0.6.4\n",
            "    Uninstalling orbax-checkpoint-0.6.4:\n",
            "      Successfully uninstalled orbax-checkpoint-0.6.4\n",
            "  Attempting uninstall: optax\n",
            "    Found existing installation: optax 0.2.3\n",
            "    Uninstalling optax-0.2.3:\n",
            "      Successfully uninstalled optax-0.2.3\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.17.0\n",
            "    Uninstalling tensorflow-2.17.0:\n",
            "      Successfully uninstalled tensorflow-2.17.0\n",
            "  Attempting uninstall: flax\n",
            "    Found existing installation: flax 0.8.5\n",
            "    Uninstalling flax-0.8.5:\n",
            "      Successfully uninstalled flax-0.8.5\n",
            "  Attempting uninstall: jupyter-server\n",
            "    Found existing installation: jupyter-server 1.24.0\n",
            "    Uninstalling jupyter-server-1.24.0:\n",
            "      Successfully uninstalled jupyter-server-1.24.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-ai-generativelanguage 0.6.10 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-aiplatform 1.71.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.16.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.27.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigtable 2.26.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-datastore 2.20.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-firestore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-functions 1.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.15.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.26.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-resource-manager 1.13.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-colab 1.0.0 requires ipykernel==5.5.6, but you have ipykernel 6.29.5 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.19.6 which is incompatible.\n",
            "inflect 7.4.0 requires typeguard>=4.0.1, but you have typeguard 2.13.3 which is incompatible.\n",
            "pandas-gbq 0.24.0 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed InquirerPy-0.3.4 arrow-1.3.0 async-lru-2.0.4 chex-0.1.86 clu-0.0.11 colorama-0.4.6 comm-0.2.2 einops-0.7.0 einshape-1.0 etils-1.7.0 fiddle-0.3.0 flatbuffers-1.12 flax-0.8.2 fqdn-1.5.1 gast-0.4.0 google-auth-oauthlib-0.4.6 googleapis-common-protos-1.63.1 graph-compression-google-research-0.0.4 graphviz-0.20.1 ipykernel-6.29.5 isoduration-20.11.0 jax-0.4.26 jax-bitempered-loss-0.0.2 jax-cuda12-pjrt-0.4.26 jax-cuda12-plugin-0.4.26 jaxlib-0.4.26 jaxtyping-0.2.28 jedi-0.19.2 json5-0.9.28 jupyter-1.1.1 jupyter-client-7.4.9 jupyter-events-0.10.0 jupyter-http-over-ws-0.0.8 jupyter-lsp-2.2.5 jupyter-server-2.14.2 jupyter-server-terminals-0.5.3 jupyterlab-4.3.0 jupyterlab-server-2.27.3 keras-2.9.0 keras-preprocessing-1.1.2 libcst-1.5.0 lingvo-0.12.7 mesh-tensorflow-0.1.21 ml-collections-1.0.0 model-pruning-google-research-0.0.5 nvidia-cuda-nvrtc-cu12-12.6.77 nvidia-cudnn-cu12-8.9.7.29 opt-einsum-3.3.0 optax-0.2.2 optax-shampoo-0.0.6 orbax-checkpoint-0.5.9 overrides-7.7.0 paxml-1.4.0 pfzy-0.3.4 portalocker-2.10.1 praxis-1.4.0 protobuf-3.19.6 pyglove-0.4.4 python-json-logger-2.0.7 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 rouge-score-0.1.2 sacrebleu-2.4.3 sentencepiece-0.1.99 seqio-nightly-0.0.17.dev20231010 t5-0.9.4 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.3 tensorflow-datasets-4.8.3 tensorflow-estimator-2.9.0 tensorflow-metadata-1.12.0 tensorflow-text-2.9.0 tensorstore-0.1.55 tf-keras-2.15.0 tfds-nightly-4.8.3.dev202303280045 timesfm-1.1.0 typeguard-2.13.3 types-python-dateutil-2.9.0.20241003 uri-template-1.3.0 utilsforecast-0.2.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "12bd0e3a080c4d82b999bf3e917b8693"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install yfinance timesfm==1.1.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XmWer0Nv_rjo",
        "outputId": "0d180a71-fc98-4e63-dbf7-08dbacdd992e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: yfinance in /usr/local/lib/python3.10/dist-packages (0.2.48)\n",
            "Requirement already satisfied: pandas>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.16.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.26.4)\n",
            "Requirement already satisfied: requests>=2.31 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.32.3)\n",
            "Requirement already satisfied: multitasking>=0.0.7 in /usr/local/lib/python3.10/dist-packages (from yfinance) (0.0.11)\n",
            "Requirement already satisfied: lxml>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (5.3.0)\n",
            "Requirement already satisfied: platformdirs>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.3.6)\n",
            "Requirement already satisfied: pytz>=2022.5 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2024.2)\n",
            "Requirement already satisfied: frozendict>=2.3.4 in /usr/local/lib/python3.10/dist-packages (from yfinance) (2.4.6)\n",
            "Requirement already satisfied: peewee>=3.16.2 in /usr/local/lib/python3.10/dist-packages (from yfinance) (3.17.7)\n",
            "Requirement already satisfied: beautifulsoup4>=4.11.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (4.12.3)\n",
            "Requirement already satisfied: html5lib>=1.1 in /usr/local/lib/python3.10/dist-packages (from yfinance) (1.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.11.1->yfinance) (2.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3.0->yfinance) (2024.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31->yfinance) (2024.8.30)\n",
            "Requirement already satisfied: utilsforecast in /usr/local/lib/python3.10/dist-packages (0.2.8)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from utilsforecast) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from utilsforecast) (24.2)\n",
            "Requirement already satisfied: pandas>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from utilsforecast) (2.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.1->utilsforecast) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.1->utilsforecast) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.1->utilsforecast) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.1->utilsforecast) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install yfinance\n",
        "!pip install utilsforecast\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "b021SYfS_87L"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
        "os.environ['JAX_PMAP_USE_TENSORSTORE'] = 'false'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOXko2V9Lv-q",
        "outputId": "fbddf19c-d666-4f71-9d69-9304e5f0693c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-12 20:15:13.715875: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "import timesfm\n",
        "import gc\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from timesfm import patched_decoder\n",
        "from timesfm import data_loader\n",
        "import yfinance as yf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "TqtZkbytlRyS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import random\n",
        "import os\n",
        "\n",
        "# Set a seed value\n",
        "seed_value = 42\n",
        "\n",
        "# Set Python random seed\n",
        "random.seed(seed_value)\n",
        "\n",
        "# Set NumPy random seed\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# Set TensorFlow random seed\n",
        "tf.random.set_seed(seed_value)\n",
        "\n",
        "# For reproducibility in other areas, like OS operations\n",
        "os.environ['PYTHONHASHSEED'] = str(seed_value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7SXbhtQ6Lv-r"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import dataclasses\n",
        "import IPython\n",
        "import IPython.display\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rcParams['figure.figsize'] = (8, 6)\n",
        "mpl.rcParams['axes.grid'] = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416,
          "referenced_widgets": [
            "be00255e1a224020aaf6d30a4740545b",
            "51fff6d6e7364ff9b8c2ada26985070c",
            "6a3c59d0c9a54933961e9aadaac9a826",
            "1abed2b98feb4278a306e9c2a1d7798c",
            "7616571b2af44906a244929ad8e1d464",
            "1a0ecc01c7c54ddfb18d073465f06049",
            "66a574cd863548868f41c45b5f05aa09",
            "1f683df68d6f4994ba09f7283e7eff4e",
            "065d3249c747495cb914a2ce395e22af",
            "865b9cfaee4d4e0999ab2dc7af431204",
            "37298eeaff984e96a5a32fb8f50a239e"
          ]
        },
        "id": "FIveKYrIABNr",
        "outputId": "60d07b4b-a257-4c9f-897f-cc0e10fa938d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-12 20:15:41.095038: W external/xla/xla/service/gpu/nvptx_compiler.cc:718] The NVIDIA driver's CUDA version is 12.2 which is older than the ptxas CUDA version (12.6.77). Because the driver is older than the ptxas version, XLA is disabling parallel compilation, which may slow down compilation. You should update your NVIDIA driver or use the NVIDIA-provided CUDA forward compatibility packages.\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be00255e1a224020aaf6d30a4740545b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constructing model weights.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
            "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
            "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. We assume `train_state` is unpadded.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Constructed model weights in 5.01 seconds.\n",
            "Restoring checkpoint from /root/.cache/huggingface/hub/models--google--timesfm-1.0-200m/snapshots/8775f7531211ac864b739fe776b0b255c277e2be/checkpoints.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:absl:For checkpoint version > 1.0, we require users to provide\n",
            "          `train_state_unpadded_shape_dtype_struct` during checkpoint\n",
            "          saving/restoring, to avoid potential silent bugs when loading\n",
            "          checkpoints to incompatible unpadded shapes of TrainState.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Restored checkpoint in 4.54 seconds.\n",
            "Jitting decoding.\n",
            "Jitted decoding in 22.56 seconds.\n"
          ]
        }
      ],
      "source": [
        "# Loading TimesFM pretrained checkpoint\n",
        "tfm = timesfm.TimesFm(\n",
        "    context_len=64,\n",
        "    horizon_len=1,\n",
        "    input_patch_len=32,\n",
        "    output_patch_len=128,\n",
        "    num_layers=20,\n",
        "    model_dims=1280,\n",
        "    backend=\"gpu\",\n",
        ")\n",
        "tfm.load_from_checkpoint(repo_id=\"google/timesfm-1.0-200m\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZkHao5_GZfP",
        "outputId": "8056f159-c668-4714-a936-34e5db4ec6f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n",
            "[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total combined data length: 29230\n",
            "Training data length: 28853\n",
            "Validation data length: 127\n",
            "Test data length: 250\n",
            "Total data length after combining: 29230\n",
            "Train end index: 28853\n",
            "Validation end index: 28980\n",
            "Total data length: 29230\n",
            "Train range: [0, 28917]\n",
            "Validation range: [28917, 29044]\n",
            "Test range: [29044, 29230]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import yfinance as yf\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# **Step 1: Load and Preprocess Data for All Stocks**\n",
        "\n",
        "# List of stock tickers\n",
        "tickers = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA', 'META', 'NVDA', 'JPM', 'V', 'NFLX']\n",
        "\n",
        "# Load daily stock data for each ticker\n",
        "all_data = []\n",
        "\n",
        "for idx, ticker in enumerate(tickers, start=1):\n",
        "    data = yf.download(ticker, start='2012-05-18', end='2024-01-01', interval='1d')\n",
        "    if data.empty:\n",
        "        print(f\"Failed to download data for {ticker}\")\n",
        "        continue\n",
        "    data.index = pd.to_datetime(data.index)\n",
        "    data = data.dropna()\n",
        "    data.reset_index(inplace=True)\n",
        "    # Handle MultiIndex columns if present\n",
        "    if isinstance(data.columns, pd.MultiIndex):\n",
        "        data.columns = data.columns.droplevel(1)\n",
        "    data.rename(columns={'Date': 'date', 'Close': 'y'}, inplace=True)\n",
        "    data['ticker'] = idx  # Replace ticker name with a unique number\n",
        "\n",
        "    final_cols = [\"date\", \"y\", \"ticker\"]\n",
        "    data = data[final_cols]\n",
        "    all_data.append(data)\n",
        "\n",
        "# Combine all stock data into one DataFrame\n",
        "combined_data = pd.concat(all_data)\n",
        "\n",
        "print(f\"Total combined data length: {len(combined_data)}\")\n",
        "\n",
        "# **Step 2: Separate Apple Data (ticker == 1)**\n",
        "\n",
        "apple_data = combined_data[combined_data['ticker'] == 1].copy()\n",
        "\n",
        "# **Step 3: Define Validation and Test Periods for Apple**\n",
        "\n",
        "# Define date ranges\n",
        "val_start_date = '2022-07-01'\n",
        "val_end_date = '2022-12-31'\n",
        "test_start_date = '2023-01-01'\n",
        "\n",
        "# Ensure 'date' column is in datetime format\n",
        "apple_data['date'] = pd.to_datetime(apple_data['date'])\n",
        "\n",
        "# Create validation data for Apple\n",
        "val_data = apple_data[(apple_data['date'] >= val_start_date) & (apple_data['date'] <= val_end_date)]\n",
        "\n",
        "# Create test data for Apple\n",
        "test_data = apple_data[apple_data['date'] >= test_start_date]\n",
        "\n",
        "# Create training data for Apple (excluding validation and test periods)\n",
        "train_data_apple = apple_data[apple_data['date'] < val_start_date]\n",
        "\n",
        "# **Step 4: Create Training Data for Non-Apple Stocks**\n",
        "\n",
        "non_apple_data = combined_data[combined_data['ticker'] != 1].copy()\n",
        "\n",
        "# **Step 5: Combine Training Data**\n",
        "\n",
        "train_data = pd.concat([train_data_apple, non_apple_data])\n",
        "\n",
        "print(f\"Training data length: {len(train_data)}\")\n",
        "print(f\"Validation data length: {len(val_data)}\")\n",
        "print(f\"Test data length: {len(test_data)}\")\n",
        "\n",
        "# **Step 6: Scale Only the Training Data**\n",
        "\n",
        "# Create a dictionary to store scalers for each ticker\n",
        "scalers = {}\n",
        "\n",
        "def scale_data(data, scalers, fit=False):\n",
        "    data=data.reset_index(drop=True)\n",
        "    data_scaled = data.copy().reset_index(drop=True)\n",
        "    for ticker in data['ticker'].unique():\n",
        "        ticker_data = data[data['ticker'] == ticker]\n",
        "        if fit:\n",
        "            scaler = StandardScaler()\n",
        "            scaler.fit(ticker_data[['y']])\n",
        "            scalers[ticker] = scaler\n",
        "        else:\n",
        "            scaler = scalers.get(ticker)\n",
        "\n",
        "        data_scaled.loc[ticker_data.index, 'y_scaled'] = scaler.transform(ticker_data[['y']])\n",
        "\n",
        "    return data_scaled\n",
        "\n",
        "# Fit scalers on training data\n",
        "train_data_scaled = scale_data(train_data, scalers, fit=True)\n",
        "\n",
        "# Scale validation and test data using the fitted scalers\n",
        "val_data_scaled = scale_data(val_data, scalers, fit=False)\n",
        "test_data_scaled = scale_data(test_data, scalers, fit=False)\n",
        "\n",
        "# **Step 7: Combine All Data and Reset Index**\n",
        "\n",
        "full_data = pd.concat([train_data_scaled, val_data_scaled, test_data_scaled]).reset_index(drop=True)\n",
        "print(f\"Total data length after combining: {len(full_data)}\")\n",
        "\n",
        "# **Step 8: Compute Index Ranges for the Data Loader**\n",
        "\n",
        "# Calculate cumulative lengths\n",
        "train_end_idx = len(train_data_scaled)\n",
        "val_end_idx = train_end_idx + len(val_data_scaled)\n",
        "total_length = len(full_data)\n",
        "\n",
        "print(f\"Train end index: {train_end_idx}\")\n",
        "print(f\"Validation end index: {val_end_idx}\")\n",
        "print(f\"Total data length: {total_length}\")\n",
        "\n",
        "# **Define Context Length and Prediction Length**\n",
        "\n",
        "context_len = 64  # Historical length\n",
        "pred_len = 1      # Prediction length\n",
        "freq = 'D'        # Daily frequency\n",
        "\n",
        "# **Compute Ranges**\n",
        "\n",
        "train_range = [0, train_end_idx + context_len]\n",
        "val_range = [train_end_idx + context_len, val_end_idx + context_len]\n",
        "test_range = [val_end_idx + context_len, total_length]\n",
        "\n",
        "print(f\"Train range: {train_range}\")\n",
        "print(f\"Validation range: {val_range}\")\n",
        "print(f\"Test range: {test_range}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FrPKz8_-yb2B",
        "outputId": "c97e3672-5136-4c37-9373-99f748bc5b42"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Price                      date           y  ticker  y_scaled\n",
              "0     2012-05-18 00:00:00+00:00   18.942142       1 -0.816202\n",
              "1     2012-05-21 00:00:00+00:00   20.045713       1 -0.791602\n",
              "2     2012-05-22 00:00:00+00:00   19.891787       1 -0.795033\n",
              "3     2012-05-23 00:00:00+00:00   20.377144       1 -0.784214\n",
              "4     2012-05-24 00:00:00+00:00   20.190001       1 -0.788386\n",
              "...                         ...         ...     ...       ...\n",
              "29225 2023-12-22 00:00:00+00:00  193.600006       1  3.077133\n",
              "29226 2023-12-26 00:00:00+00:00  193.050003       1  3.064873\n",
              "29227 2023-12-27 00:00:00+00:00  193.149994       1  3.067102\n",
              "29228 2023-12-28 00:00:00+00:00  193.580002       1  3.076687\n",
              "29229 2023-12-29 00:00:00+00:00  192.529999       1  3.053282\n",
              "\n",
              "[29230 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bd702348-26bc-4a40-9cc1-d7b0221f3437\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th>Price</th>\n",
              "      <th>date</th>\n",
              "      <th>y</th>\n",
              "      <th>ticker</th>\n",
              "      <th>y_scaled</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2012-05-18 00:00:00+00:00</td>\n",
              "      <td>18.942142</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.816202</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-05-21 00:00:00+00:00</td>\n",
              "      <td>20.045713</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.791602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2012-05-22 00:00:00+00:00</td>\n",
              "      <td>19.891787</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.795033</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2012-05-23 00:00:00+00:00</td>\n",
              "      <td>20.377144</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.784214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2012-05-24 00:00:00+00:00</td>\n",
              "      <td>20.190001</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.788386</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29225</th>\n",
              "      <td>2023-12-22 00:00:00+00:00</td>\n",
              "      <td>193.600006</td>\n",
              "      <td>1</td>\n",
              "      <td>3.077133</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29226</th>\n",
              "      <td>2023-12-26 00:00:00+00:00</td>\n",
              "      <td>193.050003</td>\n",
              "      <td>1</td>\n",
              "      <td>3.064873</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29227</th>\n",
              "      <td>2023-12-27 00:00:00+00:00</td>\n",
              "      <td>193.149994</td>\n",
              "      <td>1</td>\n",
              "      <td>3.067102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29228</th>\n",
              "      <td>2023-12-28 00:00:00+00:00</td>\n",
              "      <td>193.580002</td>\n",
              "      <td>1</td>\n",
              "      <td>3.076687</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29229</th>\n",
              "      <td>2023-12-29 00:00:00+00:00</td>\n",
              "      <td>192.529999</td>\n",
              "      <td>1</td>\n",
              "      <td>3.053282</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>29230 rows × 4 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bd702348-26bc-4a40-9cc1-d7b0221f3437')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bd702348-26bc-4a40-9cc1-d7b0221f3437 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bd702348-26bc-4a40-9cc1-d7b0221f3437');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-57404b43-9c74-4225-9993-7cd1d0c4d69f\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-57404b43-9c74-4225-9993-7cd1d0c4d69f')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-57404b43-9c74-4225-9993-7cd1d0c4d69f button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "  <div id=\"id_74ae521f-0488-4f6c-a899-1bcdcab559a7\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('full_data')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_74ae521f-0488-4f6c-a899-1bcdcab559a7 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('full_data');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "full_data",
              "summary": "{\n  \"name\": \"full_data\",\n  \"rows\": 29230,\n  \"fields\": [\n    {\n      \"column\": \"date\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2012-05-18 00:00:00+00:00\",\n        \"max\": \"2023-12-29 00:00:00+00:00\",\n        \"num_unique_values\": 2923,\n        \"samples\": [\n          \"2016-07-19 00:00:00+00:00\",\n          \"2021-11-22 00:00:00+00:00\",\n          \"2016-11-09 00:00:00+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 105.51045712457413,\n        \"min\": 0.28450000286102295,\n        \"max\": 691.6900024414062,\n        \"num_unique_values\": 24645,\n        \"samples\": [\n          39.529998779296875,\n          85.7300033569336,\n          110.36750030517578\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ticker\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 1,\n        \"max\": 10,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          9,\n          2,\n          6\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y_scaled\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.032030023502574,\n        \"min\": -1.7571777521762275,\n        \"max\": 3.643402661269306,\n        \"num_unique_values\": 27479,\n        \"samples\": [\n          -0.3806793465586867,\n          1.6576745253045564,\n          -0.2454388924476509\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ib3Y_IYpMuxE"
      },
      "outputs": [],
      "source": [
        "data_path = '/content/stocks_data.csv'\n",
        "full_data.to_csv(data_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "zMtldVchChUY"
      },
      "outputs": [],
      "source": [
        "freq = 'D'\n",
        "context_len = 64\n",
        "pred_len = 1\n",
        "batch_size = 32\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kh09wt08Cjg_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e256ac6-d1bb-4970-d843-47761521d431"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2024-11-12 20:16:35.653572: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-11-12 20:16:35.653853: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-11-12 20:16:35.654553: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-11-12 20:16:35.654730: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-11-12 20:16:35.655038: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
            "2024-11-12 20:16:35.655107: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "num_ts = 1\n",
        "# Create TimeSeriesdata loader\n",
        "dtl = data_loader.TimeSeriesdata(\n",
        "      data_path=data_path,\n",
        "      datetime_col=\"date\",\n",
        "      num_cov_cols=None,\n",
        "      cat_cov_cols=None,\n",
        "      ts_cols=[\"y_scaled\"],\n",
        "      train_range=train_range,\n",
        "      val_range=val_range,\n",
        "      test_range=test_range,\n",
        "      hist_len=context_len,\n",
        "      pred_len=pred_len,\n",
        "      batch_size=1,  # Change as per requirement\n",
        "      freq=freq,\n",
        "      normalize=False,\n",
        "      epoch_len=None,\n",
        "      holiday=False,\n",
        "      permute=False,\n",
        "  )\n",
        "train_batches = dtl.tf_dataset(mode=\"train\", shift=1).batch(batch_size)\n",
        "val_batches = dtl.tf_dataset(mode=\"val\", shift=pred_len)\n",
        "test_batches = dtl.tf_dataset(mode=\"test\", shift=pred_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABzh_VutCkkn",
        "outputId": "5f3844c8-4945-4f66-d991-f915e4c07614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "1804it [00:26, 68.47it/s] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 1, 64)\n",
            "(8, 8, 64)\n",
            "(8, 1, 64)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "for tbatch in tqdm(train_batches.as_numpy_iterator()):\n",
        "    pass\n",
        "print(tbatch[0].shape)\n",
        "print(tbatch[1].shape)\n",
        "print(tbatch[2].shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIBPb071Lv-w"
      },
      "source": [
        "# MAE on the test split for the pretrained TimesFM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ukVMJKv8Lv-x",
        "outputId": "51a534f0-cd10-479a-92a6-cac53d0feeb4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "186it [00:03, 52.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.0026948237791657448\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "mse_losses = []\n",
        "for batch in tqdm(test_batches.as_numpy_iterator()):\n",
        "    past = batch[0]\n",
        "    actuals = batch[3]\n",
        "\n",
        "    _, forecasts = tfm.forecast(list(past), [0] * past.shape[0])\n",
        "    forecasts = forecasts[:, 0 : actuals.shape[1], 5]\n",
        "\n",
        "    mse_losses.append(np.square(forecasts - actuals).mean())\n",
        "\n",
        "print(f\"MSE: {np.mean(mse_losses)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K7CumC-_HO0W"
      },
      "source": [
        "# Fine-tuning the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "wi-S2j1NLv-x"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "from jax import numpy as jnp\n",
        "from praxis import pax_fiddle\n",
        "from praxis import py_utils\n",
        "from praxis import pytypes\n",
        "from praxis import base_model\n",
        "from praxis import optimizers\n",
        "from praxis import schedules\n",
        "from praxis import base_hyperparams\n",
        "from praxis import base_layer\n",
        "from paxml import tasks_lib\n",
        "from paxml import trainer_lib\n",
        "from paxml import checkpoints\n",
        "from paxml import learners\n",
        "from paxml import partitioning\n",
        "from paxml import checkpoint_types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "2ZGLjnuhLv-x"
      },
      "outputs": [],
      "source": [
        "NestedMap = py_utils.NestedMap\n",
        "WeightInit = base_layer.WeightInit\n",
        "WeightHParams = base_layer.WeightHParams\n",
        "InstantiableParams = py_utils.InstantiableParams\n",
        "JTensor = pytypes.JTensor\n",
        "NpTensor = pytypes.NpTensor\n",
        "WeightedScalars = pytypes.WeightedScalars\n",
        "instantiate = base_hyperparams.instantiate\n",
        "LayerTpl = pax_fiddle.Config[base_layer.BaseLayer]\n",
        "AuxLossStruct = base_layer.AuxLossStruct\n",
        "\n",
        "AUX_LOSS = base_layer.AUX_LOSS\n",
        "template_field = base_layer.template_field\n",
        "\n",
        "# Standard prng key names\n",
        "PARAMS = base_layer.PARAMS\n",
        "RANDOM = base_layer.RANDOM\n",
        "\n",
        "key = jax.random.PRNGKey(seed=1234)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "cd1NHVrRLv-0"
      },
      "outputs": [],
      "source": [
        "model = pax_fiddle.Config(\n",
        "    patched_decoder.PatchedDecoderFinetuneModel,\n",
        "    name='patched_decoder_finetune',\n",
        "    core_layer_tpl=tfm.model_p,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-JmTP2ItLv-0"
      },
      "outputs": [],
      "source": [
        "\n",
        "@pax_fiddle.auto_config\n",
        "def build_learner() -> learners.Learner:\n",
        "  return pax_fiddle.Config(\n",
        "      learners.Learner,\n",
        "      name='learner',\n",
        "      loss_name='avg_qloss',\n",
        "      optimizer=optimizers.Adam(\n",
        "          epsilon=1e-7,\n",
        "          clip_threshold=1e2,\n",
        "          learning_rate=1e-2,\n",
        "          lr_schedule=pax_fiddle.Config(\n",
        "              schedules.Cosine,\n",
        "              initial_value=1e-3,\n",
        "              final_value=1e-4,\n",
        "              total_steps=40000,\n",
        "          ),\n",
        "          ema_decay=0.9999,\n",
        "      ),\n",
        "      # Linear probing i.e we hold the transformer layers fixed.\n",
        "      bprop_variable_exclusion=['.*/stacked_transformer_layer/.*'],\n",
        "  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BwmRar8GLv-1"
      },
      "outputs": [],
      "source": [
        "\n",
        "task_p = tasks_lib.SingleTask(\n",
        "    name='ts-learn',\n",
        "    model=model,\n",
        "    train=tasks_lib.SingleTask.Train(\n",
        "        learner=build_learner(),\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0HGp8DzGLv-1",
        "outputId": "2e8d7905-4573-437a-fe7d-a76d29015b8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_devices: 1\n",
            "device kind: Tesla T4\n"
          ]
        }
      ],
      "source": [
        "task_p.model.ici_mesh_shape = [1, 1, 1]\n",
        "task_p.model.mesh_axis_names = ['replica', 'data', 'mdl']\n",
        "\n",
        "DEVICES = np.array(jax.devices()).reshape([1, 1, 1])\n",
        "MESH = jax.sharding.Mesh(DEVICES, ['replica', 'data', 'mdl'])\n",
        "\n",
        "num_devices = jax.local_device_count()\n",
        "print(f'num_devices: {num_devices}')\n",
        "print(f'device kind: {jax.local_devices()[0].device_kind}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "PCuOfttnLv-1"
      },
      "outputs": [],
      "source": [
        "jax_task = task_p\n",
        "key, init_key = jax.random.split(key)\n",
        "\n",
        "# To correctly prepare a batch of data for model initialization (now that shape\n",
        "# inference is merged), we take one devices*batch_size tensor tuple of data,\n",
        "# slice out just one batch, then run the prepare_input_batch function over it.\n",
        "\n",
        "\n",
        "def process_train_batch(batch):\n",
        "\n",
        "    past_ts = batch[0].reshape(len(batch[2]) * num_ts, -1)\n",
        "    actual_ts = batch[3].reshape(len(batch[2]) * num_ts, -1)\n",
        "    return NestedMap(input_ts=past_ts, actual_ts=actual_ts)\n",
        "\n",
        "\n",
        "def process_eval_batch(batch):\n",
        "    past_ts = batch[0]\n",
        "    actual_ts = batch[3]\n",
        "    return NestedMap(input_ts=past_ts, actual_ts=actual_ts)\n",
        "\n",
        "\n",
        "jax_model_states, _ = trainer_lib.initialize_model_state(\n",
        "    jax_task,\n",
        "    init_key,\n",
        "    process_train_batch(tbatch),\n",
        "    checkpoint_type=checkpoint_types.CheckpointType.GDA,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNSyx49ILv-2",
        "outputId": "0030b6ec-4888-4ee1-d969-531f60f9966b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "jax_model_states.mdl_vars['params']['core_layer'] = tfm._train_state.mdl_vars['params']\n",
        "jax_vars = jax_model_states.mdl_vars\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "M1wI6BR9Lv-2"
      },
      "outputs": [],
      "source": [
        "jax_task = task_p\n",
        "\n",
        "\n",
        "def train_step(states, prng_key, inputs):\n",
        "  return trainer_lib.train_step_single_learner(\n",
        "      jax_task, states, prng_key, inputs\n",
        "  )\n",
        "\n",
        "\n",
        "def eval_step(states, prng_key, inputs):\n",
        "  states = states.to_eval_state()\n",
        "  return trainer_lib.eval_step_single_learner(\n",
        "      jax_task, states, prng_key, inputs\n",
        "  )\n",
        "\n",
        "key, train_key, eval_key = jax.random.split(key, 3)\n",
        "train_prng_seed = jax.random.split(train_key, num=jax.local_device_count())\n",
        "eval_prng_seed = jax.random.split(eval_key, num=jax.local_device_count())\n",
        "\n",
        "p_train_step = jax.pmap(train_step, axis_name='batch')\n",
        "p_eval_step = jax.pmap(eval_step, axis_name='batch')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Gp79Rq9TLv-2"
      },
      "outputs": [],
      "source": [
        "replicated_jax_states = trainer_lib.replicate_model_state(jax_model_states)\n",
        "replicated_jax_vars = replicated_jax_states.mdl_vars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "hUUXA3rLLv-2"
      },
      "outputs": [],
      "source": [
        "best_eval_loss = 1e7\n",
        "step_count = 0\n",
        "patience = 0\n",
        "NUM_EPOCHS = 100\n",
        "PATIENCE = 5\n",
        "TRAIN_STEPS_PER_EVAL = 1000\n",
        "CHECKPOINT_DIR='/content'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "WHCWNE6oLv-3"
      },
      "outputs": [],
      "source": [
        "def reshape_batch_for_pmap(batch, num_devices):\n",
        "  def _reshape(input_tensor):\n",
        "    bsize = input_tensor.shape[0]\n",
        "    residual_shape = list(input_tensor.shape[1:])\n",
        "    nbsize = bsize // num_devices\n",
        "    return jnp.reshape(input_tensor, [num_devices, nbsize] + residual_shape)\n",
        "\n",
        "  return jax.tree.map(_reshape, batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "LDq6RwY8cg8r"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/checkpoint*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfTp0M2sLv-3",
        "outputId": "59ad96b1-0edd-4169-8d1f-24ae200e1218"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__________________Epoch: 0__________________\n",
            "Train loss at end of epoch 0: 0.19216634333133698\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:13,  9.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 0: 0.39031529426574707\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
            "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
            "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. Saving the\n",
            "        shapes of train_state  as the unpadded shapes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving checkpoint.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:SaveArgs.aggregate is deprecated, please use custom TypeHandler (https://orbax.readthedocs.io/en/latest/custom_handlers.html#typehandler) or contact Orbax team to migrate before May 1st, 2024. If your Pytree has empty ([], {}, None) values then use PyTreeCheckpointHandler(..., write_tree_metadata=True, ...) or use StandardCheckpointHandler to avoid TypeHandler Registry error. Please note that PyTreeCheckpointHandler.write_tree_metadata default value is already set to True.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "__________________Epoch: 1__________________\n",
            "Train loss at end of epoch 1: 0.18404361605644226\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 102.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 1: 0.3892664611339569\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
            "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
            "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. Saving the\n",
            "        shapes of train_state  as the unpadded shapes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving checkpoint.\n",
            "__________________Epoch: 2__________________\n",
            "Train loss at end of epoch 2: 0.17941910028457642\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 102.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 2: 0.384927898645401\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
            "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
            "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. Saving the\n",
            "        shapes of train_state  as the unpadded shapes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving checkpoint.\n",
            "__________________Epoch: 3__________________\n",
            "Train loss at end of epoch 3: 0.1759457141160965\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 102.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 3: 0.385672926902771\n",
            "patience: 1\n",
            "__________________Epoch: 4__________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at end of epoch 4: 0.17308156192302704\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 101.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 4: 0.3848976492881775\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
            "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
            "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. Saving the\n",
            "        shapes of train_state  as the unpadded shapes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving checkpoint.\n",
            "__________________Epoch: 5__________________\n",
            "Train loss at end of epoch 5: 0.17091251909732819\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 102.10it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 5: 0.3846028447151184\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
            "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
            "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. Saving the\n",
            "        shapes of train_state  as the unpadded shapes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving checkpoint.\n",
            "Unwaited save to Google Drive.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
            "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
            "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. Saving the\n",
            "        shapes of train_state  as the unpadded shapes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved at step 10824, epoch 5\n",
            "__________________Epoch: 6__________________\n",
            "Train loss at end of epoch 6: 0.16787712275981903\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 102.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 6: 0.3830512464046478\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
            "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
            "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. Saving the\n",
            "        shapes of train_state  as the unpadded shapes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving checkpoint.\n",
            "__________________Epoch: 7__________________\n",
            "Train loss at end of epoch 7: 0.16593965888023376\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 100.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 7: 0.38071873784065247\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
            "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
            "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. Saving the\n",
            "        shapes of train_state  as the unpadded shapes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving checkpoint.\n",
            "__________________Epoch: 8__________________\n",
            "Train loss at end of epoch 8: 0.16370373964309692\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 102.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 8: 0.38054531812667847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
            "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
            "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. Saving the\n",
            "        shapes of train_state  as the unpadded shapes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving checkpoint.\n",
            "__________________Epoch: 9__________________\n",
            "Train loss at end of epoch 9: 0.161928191781044\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 102.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 9: 0.3788645565509796\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
            "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
            "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. Saving the\n",
            "        shapes of train_state  as the unpadded shapes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving checkpoint.\n",
            "__________________Epoch: 10__________________\n",
            "Train loss at end of epoch 10: 0.16020415723323822\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 102.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 10: 0.38287580013275146\n",
            "patience: 1\n",
            "__________________Epoch: 11__________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at end of epoch 11: 0.15845631062984467\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 101.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 11: 0.378116637468338\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
            "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
            "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. Saving the\n",
            "        shapes of train_state  as the unpadded shapes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving checkpoint.\n",
            "Unwaited save to Google Drive.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
            "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
            "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. Saving the\n",
            "        shapes of train_state  as the unpadded shapes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checkpoint saved at step 21648, epoch 11\n",
            "__________________Epoch: 12__________________\n",
            "Train loss at end of epoch 12: 0.15676924586296082\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 100.85it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 12: 0.37298524379730225\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
            "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
            "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. Saving the\n",
            "        shapes of train_state  as the unpadded shapes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving checkpoint.\n",
            "__________________Epoch: 13__________________\n",
            "Train loss at end of epoch 13: 0.15540054440498352\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 102.44it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 13: 0.3788106143474579\n",
            "patience: 1\n",
            "__________________Epoch: 14__________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at end of epoch 14: 0.15408091247081757\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 102.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 14: 0.37738797068595886\n",
            "patience: 2\n",
            "__________________Epoch: 15__________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at end of epoch 15: 0.15299861133098602\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 102.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 15: 0.3770844638347626\n",
            "patience: 3\n",
            "__________________Epoch: 16__________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train loss at end of epoch 16: 0.15191251039505005\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 100.65it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 16: 0.3791418969631195\n",
            "patience: 4\n",
            "__________________Epoch: 17__________________\n",
            "Train loss at end of epoch 17: 0.15103602409362793\n",
            "Starting eval.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "127it [00:01, 102.15it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval loss at end of epoch 17: 0.37777671217918396\n",
            "patience: 5\n",
            "Early stopping.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "save_count = 0\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    print(f\"__________________Epoch: {epoch}__________________\", flush=True)\n",
        "\n",
        "    # Train phase\n",
        "    train_its = train_batches.as_numpy_iterator()\n",
        "    if patience >= PATIENCE:\n",
        "        print(\"Early stopping.\", flush=True)\n",
        "        break\n",
        "\n",
        "    train_losses = []  # Initialize train losses for the epoch\n",
        "    for batch in train_its:\n",
        "        if patience >= PATIENCE:\n",
        "            print(\"Early stopping.\", flush=True)\n",
        "            break\n",
        "\n",
        "        tbatch = process_train_batch(batch)\n",
        "        tbatch = reshape_batch_for_pmap(tbatch, num_devices)\n",
        "        replicated_jax_states, step_fun_out = p_train_step(\n",
        "            replicated_jax_states, train_prng_seed, tbatch\n",
        "        )\n",
        "        train_losses.append(step_fun_out.loss[0])\n",
        "\n",
        "        # Increment step count\n",
        "        step_count += 1\n",
        "\n",
        "    # Calculate and print average train loss for the epoch\n",
        "    avg_train_loss = np.mean(train_losses)\n",
        "    print(f\"Train loss at end of epoch {epoch}: {avg_train_loss}\", flush=True)\n",
        "\n",
        "    # Eval phase at the end of the epoch\n",
        "    print(\"Starting eval.\", flush=True)\n",
        "    val_its = val_batches.as_numpy_iterator()\n",
        "    eval_losses = []  # Initialize eval losses for the epoch\n",
        "\n",
        "    for ev_batch in tqdm(val_its):\n",
        "        ebatch = process_eval_batch(ev_batch)\n",
        "        ebatch = reshape_batch_for_pmap(ebatch, num_devices)\n",
        "        _, step_fun_out = p_eval_step(replicated_jax_states, eval_prng_seed, ebatch)\n",
        "        eval_losses.append(step_fun_out.loss[0])\n",
        "\n",
        "    # Calculate and print average eval loss for the epoch\n",
        "    mean_loss = np.mean(eval_losses)\n",
        "    print(f\"Eval loss at end of epoch {epoch}: {mean_loss}\", flush=True)\n",
        "\n",
        "    # Check for checkpoint saving and patience logic\n",
        "    if mean_loss < best_eval_loss or np.isnan(mean_loss):\n",
        "        best_eval_loss = mean_loss\n",
        "        print(\"Saving checkpoint.\")\n",
        "        jax_state_for_saving = py_utils.maybe_unreplicate_for_fully_replicated(\n",
        "            replicated_jax_states\n",
        "        )\n",
        "        save_count += 1\n",
        "        if save_count % 5 == 0:\n",
        "            print(\"Unwaited save to Google Drive.\")\n",
        "            checkpoints.save_checkpoint(\n",
        "                jax_state_for_saving, '/content/drive/MyDrive', overwrite=True,\n",
        "            )\n",
        "            with open(os.path.join( '/content/drive/MyDrive', 'train_state_info.pkl'), 'wb') as f:\n",
        "               pickle.dump({'step_count': step_count, 'epoch': epoch}, f)\n",
        "               print(f\"Checkpoint saved at step {step_count}, epoch {epoch}\")\n",
        "        checkpoints.save_checkpoint(\n",
        "            jax_state_for_saving, CHECKPOINT_DIR, overwrite=True\n",
        "        )\n",
        "        patience = 0  # Reset patience since we improved\n",
        "        del jax_state_for_saving\n",
        "        gc.collect()\n",
        "    else:\n",
        "        patience += 1\n",
        "        print(f\"patience: {patience}\")\n",
        "\n",
        "    # Early stopping check\n",
        "    if patience >= PATIENCE:\n",
        "        print(\"Early stopping.\", flush=True)\n",
        "        break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "dCPjpDYSLv-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb659f8b-afa2-4b42-b9cb-030875dac578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:No registered CheckpointArgs found for handler type: <class 'paxml.checkpoints.FlaxCheckpointHandler'>\n",
            "WARNING:absl:Configured `CheckpointManager` using deprecated legacy API. Please follow the instructions at https://orbax.readthedocs.io/en/latest/api_refactor.html to migrate by May 1st, 2024.\n",
            "WARNING:absl:train_state_unpadded_shape_dtype_struct is not provided. We assume `train_state` is unpadded.\n",
            "ERROR:absl:For checkpoint version > 1.0, we require users to provide\n",
            "          `train_state_unpadded_shape_dtype_struct` during checkpoint\n",
            "          saving/restoring, to avoid potential silent bugs when loading\n",
            "          checkpoints to incompatible unpadded shapes of TrainState.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "23452\n",
            "Jitting decoding.\n",
            "Jitted decoding in 20.48 seconds.\n"
          ]
        }
      ],
      "source": [
        "train_state = checkpoints.restore_checkpoint(jax_model_states, CHECKPOINT_DIR)\n",
        "print(train_state.step)\n",
        "tfm._train_state.mdl_vars['params'] = train_state.mdl_vars['params']['core_layer']\n",
        "tfm.jit_decode()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "b-v5eQ7mLv-4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ea167f-178c-4c27-8bd8-3973abda7ebe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "186it [00:03, 57.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mse: 0.0023281839676201344\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "mse_losses = []\n",
        "for batch in tqdm(test_batches.as_numpy_iterator()):\n",
        "    past = batch[0]\n",
        "    actuals = batch[3]\n",
        "    _, forecasts = tfm.forecast(list(past), [0] * past.shape[0])\n",
        "    forecasts = forecasts[:, 0 : actuals.shape[1], 5]\n",
        "    mse_losses.append(np.square(forecasts - actuals))\n",
        "\n",
        "print(f\"Mse: {np.mean(mse_losses)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "4uMn25yvi1XB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1188529-2e27-4e32-e257-8732e966dd80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.742681289884589"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "from collections import defaultdict\n",
        "# Download stock data from Yahoo Finance\n",
        "ticker = 'AAPL'  # Example: Apple Inc.\n",
        "data = yf.download(ticker, start=\"2023-01-01\", end=\"2024-01-01\")\n",
        "data = data.dropna()\n",
        "\n",
        "df = data[['Close']].reset_index()\n",
        "df.columns = ['date', 'close']\n",
        "df['date'] = pd.to_datetime(df['date'])\n",
        "df.set_index('date', inplace=True)\n",
        "\n",
        "\n",
        "def get_batched_data_fn(batch_size: int = 32, context_len: int = 32, horizon_len: int = 1):\n",
        "    examples = defaultdict(list)\n",
        "    num_examples = 0\n",
        "    for start in range(0, len(df) - (context_len + horizon_len), horizon_len):\n",
        "        num_examples += 1\n",
        "        context_end = start + context_len\n",
        "        examples[\"inputs\"].append(df[\"close\"][start:context_end].tolist())\n",
        "        examples[\"outputs\"].append(df[\"close\"][context_end:context_end + horizon_len].tolist())\n",
        "        examples[\"dates\"].append(df.index[start:context_end + horizon_len].tolist())  # Add dates to examples\n",
        "\n",
        "    def data_fn():\n",
        "        for i in range(1 + (num_examples - 1) // batch_size):\n",
        "            yield {k: v[(i * batch_size): ((i + 1) * batch_size)] for k, v in examples.items()}\n",
        "\n",
        "    return data_fn\n",
        "context_len=64\n",
        "input_patch_len=32\n",
        "horizon_len=1\n",
        "batch_size=1\n",
        "\n",
        "input_data = get_batched_data_fn(batch_size=batch_size, context_len=context_len, horizon_len=horizon_len)\n",
        "\n",
        "results = []\n",
        "# Process in smaller sub-batches\n",
        "for i, example in enumerate(input_data()):\n",
        "    raw_forecast, _ = tfm.forecast(\n",
        "        inputs=example[\"inputs\"], freq=[0] * len(example[\"inputs\"])\n",
        "    )\n",
        "    for j in range(len(example[\"inputs\"])):\n",
        "        result = {\n",
        "            'input_index': j,\n",
        "            'train_start_date': str(example[\"dates\"][j][0]),\n",
        "            'train_end_date': str(example[\"dates\"][j][-2]),\n",
        "            'predict_date': str(example[\"dates\"][j][-1]),\n",
        "            'raw_forecast': raw_forecast[j][0],\n",
        "            'y_actual': example[\"outputs\"][j][0],\n",
        "            'batch_size': batch_size,\n",
        "            'context_len': context_len,\n",
        "            'input_patch_len': input_patch_len\n",
        "        }\n",
        "        results.append(result)\n",
        "results_df = pd.DataFrame(results)\n",
        "from sklearn.metrics import mean_squared_error, accuracy_score\n",
        "mean_squared_error(results_df['y_actual'], results_df['raw_forecast'])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "be00255e1a224020aaf6d30a4740545b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_51fff6d6e7364ff9b8c2ada26985070c",
              "IPY_MODEL_6a3c59d0c9a54933961e9aadaac9a826",
              "IPY_MODEL_1abed2b98feb4278a306e9c2a1d7798c"
            ],
            "layout": "IPY_MODEL_7616571b2af44906a244929ad8e1d464"
          }
        },
        "51fff6d6e7364ff9b8c2ada26985070c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a0ecc01c7c54ddfb18d073465f06049",
            "placeholder": "​",
            "style": "IPY_MODEL_66a574cd863548868f41c45b5f05aa09",
            "value": "Fetching 5 files: 100%"
          }
        },
        "6a3c59d0c9a54933961e9aadaac9a826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f683df68d6f4994ba09f7283e7eff4e",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_065d3249c747495cb914a2ce395e22af",
            "value": 5
          }
        },
        "1abed2b98feb4278a306e9c2a1d7798c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_865b9cfaee4d4e0999ab2dc7af431204",
            "placeholder": "​",
            "style": "IPY_MODEL_37298eeaff984e96a5a32fb8f50a239e",
            "value": " 5/5 [00:00&lt;00:00, 114.48it/s]"
          }
        },
        "7616571b2af44906a244929ad8e1d464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a0ecc01c7c54ddfb18d073465f06049": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66a574cd863548868f41c45b5f05aa09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f683df68d6f4994ba09f7283e7eff4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "065d3249c747495cb914a2ce395e22af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "865b9cfaee4d4e0999ab2dc7af431204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37298eeaff984e96a5a32fb8f50a239e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}